{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f61fed-b2cd-40f9-a8a8-6638f6b23905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "778c58a5-f4c8-4971-b3d1-5bf1c07f3f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('board_grade.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f6629e-ae07-4941-858b-4c8a338999fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data[:, 1], data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de2e73b2-7e71-484b-aaf8-3c457ecf62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y.shape[0]):\n",
    "    try:\n",
    "        assert y[i].shape == y[i+1].shape\n",
    "    except:\n",
    "        if i + 1 < y.shape[0]:\n",
    "            print(y[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "144a4d2f-a1ce-4ee1-b2aa-3b0740d7bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_boards = np.stack(x).reshape(-1, 18, 11, 2)\n",
    "all_classes = np.stack(y).reshape(-1, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43e808c-52d7-4024-b014-4ad68eac4105",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boards, train_classes, valid_boards, valid_classes = train_test_split(all_boards, all_classes, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e324a6b2-79d7-4663-a45d-66b13e4c5e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14264, 18, 11, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_boards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef68c347-ef32-44fa-a044-e567e735c17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | A B C D E F G H I J K \n",
      "--------------------------\n",
      "18 | - - - - E - - - - - - \n",
      "17 | - - - - - - - - - - - \n",
      "16 | - - - - - - - - - - - \n",
      "15 | - - - - M - - - - - - \n",
      "14 | - - - - - - - - - - - \n",
      "13 | - - - - - - M - - - - \n",
      "12 | - - - - - - - - - - - \n",
      "11 | - - - - - - - - M - M \n",
      "10 | - - - - - - - - - - - \n",
      " 9 | - - - - - - - - - - - \n",
      " 8 | - - - - - - - - - M - \n",
      " 7 | - - - - - - - - - - - \n",
      " 6 | - - - - - - - - - - - \n",
      " 5 | - - - - - S - - - - - \n",
      " 4 | - - - - - - - - - - - \n",
      " 3 | - - - - - - - - - - - \n",
      " 2 | - - - - - - - - - - - \n",
      " 1 | - - - - - - - - - - - \n",
      "--------------------------\n",
      "Problem Grade: V4 (6B+)\n",
      "\n",
      "\n",
      "   | A B C D E F G H I J K \n",
      "--------------------------\n",
      "18 | - - E - - - - - - - - \n",
      "17 | - - - - - - - - - - - \n",
      "16 | - - - M - - - - - - - \n",
      "15 | - - - - - - - - - - - \n",
      "14 | - - - - - - - - - - - \n",
      "13 | - - - M - - - - - - - \n",
      "12 | - - - - - - - - M - - \n",
      "11 | - - - - - - - - - - - \n",
      "10 | - - - - - - - - - - - \n",
      " 9 | - - - - - M - - - - - \n",
      " 8 | - - - - - - - - - - - \n",
      " 7 | - - - - - - - - - - - \n",
      " 6 | - - - M - - - - - - - \n",
      " 5 | - - - - - - - - - - - \n",
      " 4 | - - - - - - - - - - - \n",
      " 3 | - - - S - - - - - - - \n",
      " 2 | - - - - - - - - - - - \n",
      " 1 | - - - - - - - - - - - \n",
      "--------------------------\n",
      "Problem Grade: V8 (7B/+)\n",
      "\n",
      "\n",
      "   | A B C D E F G H I J K \n",
      "--------------------------\n",
      "18 | - - E - - - - - - - - \n",
      "17 | - - - - - - - - - - - \n",
      "16 | - - - - - - - - - - - \n",
      "15 | - - - - M - - - - - - \n",
      "14 | - - - - - - - - - - - \n",
      "13 | - - - - M - - - - - - \n",
      "12 | - - - - - - - - - - - \n",
      "11 | - - - - - - - - - - - \n",
      "10 | - - - M - - - - - - - \n",
      " 9 | - - - - - - - - - - - \n",
      " 8 | - M - - - - - - - - - \n",
      " 7 | - - - - - - - - - - - \n",
      " 6 | - - - - - - - - - - - \n",
      " 5 | S - - - - - - - - - - \n",
      " 4 | - - - - - - - - - - - \n",
      " 3 | - - - - - - - - - - - \n",
      " 2 | - - - - - - - - - - - \n",
      " 1 | - - - - - - - - - - - \n",
      "--------------------------\n",
      "Problem Grade: V5 (6C/+)\n"
     ]
    }
   ],
   "source": [
    "grade_to_list = {\n",
    "    \"V4 (6B+)\": tuple([0,0,0,0,0,0,0]),\n",
    "    \"V5 (6C/+)\": tuple([1,0,0,0,0,0,0]),\n",
    "    \"V6 (7A)\": tuple([1,1,0,0,0,0,0]),\n",
    "    \"V7 (7A+)\": tuple([1,1,1,0,0,0,0]),\n",
    "    \"V8 (7B/+)\": tuple([1,1,1,1,0,0,0]),\n",
    "    \"V9 (7C)\": tuple([1,1,1,1,1,0,0]),\n",
    "    \"V10 (7C+)\": tuple([1,1,1,1,1,1,0]),\n",
    "    \"V11 (8A) or harder\": tuple([1,1,1,1,1,1,1]),\n",
    "}\n",
    "\n",
    "grade_num_to_list = {\n",
    "    0: tuple([0,0,0,0,0,0,0]),\n",
    "    1: tuple([1,0,0,0,0,0,0]),\n",
    "    2: tuple([1,1,0,0,0,0,0]),\n",
    "    3: tuple([1,1,1,0,0,0,0]),\n",
    "    4: tuple([1,1,1,1,0,0,0]),\n",
    "    5: tuple([1,1,1,1,1,0,0]),\n",
    "    6: tuple([1,1,1,1,1,1,0]),\n",
    "    7: tuple([1,1,1,1,1,1,1]),\n",
    "}\n",
    "\n",
    "print_dict = {\n",
    "    0: \"M\",\n",
    "    1: \"S\",\n",
    "    2: \"E\"\n",
    "}\n",
    "\n",
    "list_to_grade = dict((v,k) for k,v in grade_to_list.items())\n",
    "list_to_grade_num = dict((v,k) for k,v in grade_num_to_list.items())\n",
    "\n",
    "def print_board_bar():\n",
    "    for i in range(26):\n",
    "        print(\"-\", end=\"\")\n",
    "    print()\n",
    "\n",
    "def print_board(board, grade_list):\n",
    "    print(\" \"*3, end=\"| \")\n",
    "    for i in range(11):\n",
    "        print(f\"{chr(i + 65)}\", end=\" \")\n",
    "    print()\n",
    "    print_board_bar()\n",
    "    for i in range(18):\n",
    "        print(f\"{18 - i:2} |\", end=\" \")\n",
    "        for j in range(11):\n",
    "            num_printed = False\n",
    "            for c in range(2):\n",
    "                if board[17 - i, j, c] > 0:\n",
    "                    char = \"M\"\n",
    "                    if c > 0:\n",
    "                        char = \"S\" if i >= 12 else \"E\"\n",
    "                    print(char, end=\" \")  \n",
    "                    num_printed = True\n",
    "            if not num_printed:\n",
    "                print(\"-\", end=\" \")\n",
    "        print()\n",
    "    print_board_bar()\n",
    "        \n",
    "    print(f\"Problem Grade: {list_to_grade[tuple([round(x) for x in grade_list])]}\")\n",
    "\n",
    "def print_problem(problem_num):\n",
    "    if problem_num < 0 or problem_num > all_boards.shape[0]:\n",
    "        print(\"problem number out of bounds!\")\n",
    "        return -1\n",
    "    print_board(all_boards[problem_num], all_classes[problem_num])\n",
    "\n",
    "print_problem(1)\n",
    "print()\n",
    "print()\n",
    "print_problem(5)\n",
    "print()\n",
    "print()\n",
    "print_problem(499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4acd7cb-d4c3-48a0-8e3d-85d48242ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e2bda3b-b440-4708-8e3f-ccc954c27ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "x_tensor = torch.tensor(all_boards, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(all_classes, dtype=torch.float32)\n",
    "# create the dataset\n",
    "dataset = data.TensorDataset(x_tensor, y_tensor)\n",
    "val_size = int(len(dataset)*0.2)\n",
    "train_size = len(dataset)- int(len(dataset)*0.2)\n",
    "train_dataset, val_dataset = data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62095b30-6763-46ad-a7ff-2efd00d35848",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 18 * 11 * 2\n",
    "OUTPUT_DIM = 7\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    thresh_pred = (y_pred > 0).float()\n",
    "    thresh_y = (y > 0).float()\n",
    "    correct = torch.tensor(0).to(\"cuda\")\n",
    "    for i in range(y.shape[0]):\n",
    "        correct += thresh_y[i].equal(thresh_pred[i])\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def calculate_plus_minus_one(y_pred, y):\n",
    "    y_pred = (y_pred > 0).float().to(\"cuda\")\n",
    "    y = (y > 0).float().to(\"cuda\")\n",
    "    correct = torch.tensor(0).to(\"cuda\")\n",
    "    for i in range(y.shape[0]):\n",
    "        correct += (y_pred[i].eq(y[i]).sum() >= OUTPUT_DIM - 1)\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35709637-b69e-417b-b3b0-140a3d9f1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_fc = nn.Linear(input_dim, 40)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.hidden_fc = nn.Linear(40, 20)\n",
    "        self.output_fc = nn.Linear(20, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [batch size, height, width]\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        # x = [batch size, height * width]\n",
    "        h_1 = self.dropout(F.mish(self.input_fc(x)))\n",
    "        # h_1 = [batch size, 250]\n",
    "        h_2 = self.dropout(F.mish(self.hidden_fc(h_1)))\n",
    "        # h_2 = [batch size, 100]\n",
    "        y_pred = self.output_fc(h_2)\n",
    "        # y_pred = [batch size, output dim]\n",
    "        return y_pred, h_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2373b0-d00a-4006-aa1c-05d330ffa113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 0.084 | Train Acc: 41.48% | Train Acc +/- 1 Grade: 79.90%\n",
      "\t Val. Loss: 0.066 |  Val. Acc: 50.20% |  Val. Acc +/- 1 Grade: 87.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\tTrain Loss: 0.072 | Train Acc: 46.56% | Train Acc +/- 1 Grade: 84.34%\n",
      "\t Val. Loss: 0.064 |  Val. Acc: 51.18% |  Val. Acc +/- 1 Grade: 88.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\tTrain Loss: 0.070 | Train Acc: 47.11% | Train Acc +/- 1 Grade: 85.00%\n",
      "\t Val. Loss: 0.064 |  Val. Acc: 51.04% |  Val. Acc +/- 1 Grade: 87.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\tTrain Loss: 0.068 | Train Acc: 48.56% | Train Acc +/- 1 Grade: 85.56%\n",
      "\t Val. Loss: 0.063 |  Val. Acc: 50.92% |  Val. Acc +/- 1 Grade: 87.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 9s\n",
      "\tTrain Loss: 0.067 | Train Acc: 48.45% | Train Acc +/- 1 Grade: 85.69%\n",
      "\t Val. Loss: 0.062 |  Val. Acc: 52.41% |  Val. Acc +/- 1 Grade: 88.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 2741/3567 [00:06<00:01, 437.89it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# fix the random seed; don't modify this\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MLP(INPUT_DIM, OUTPUT_DIM)\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_iterator = data.DataLoader(train_dataset,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(val_dataset,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([1,1,1.25,1.5,1.5,3.5,7]))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_plus_minus = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, _ = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        plus_minus = calculate_plus_minus_one(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_plus_minus += plus_minus.item()\n",
    "\n",
    "    return epoch_loss / (len(iterator) * BATCH_SIZE), epoch_acc / len(iterator), epoch_plus_minus / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_plus_minus = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            plus_minus = calculate_plus_minus_one(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_plus_minus += plus_minus.item()\n",
    "\n",
    "    return epoch_loss / (len(iterator) * BATCH_SIZE), epoch_acc / len(iterator), epoch_plus_minus / len(iterator)\n",
    "\n",
    "\n",
    "EPOCHS = 25\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc, train_plus_minus = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc, valid_plus_minus = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train Acc +/- 1 Grade: {train_plus_minus*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% |  Val. Acc +/- 1 Grade: {valid_plus_minus*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d279fd-82fd-445c-b0d0-51614c6b0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# grab a boulder from the validation set and see what the net thinks\n",
    "view_iterator = data.DataLoader(val_dataset,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=1)\n",
    "\n",
    "\n",
    "# set it up properly for viewing + prediction\n",
    "board, grade = next(iter(view_iterator))\n",
    "view_board = board.reshape(18, 11, 2)\n",
    "view_grade = grade.reshape(7)\n",
    "board = board.to(device)\n",
    "grade = grade.to(device)\n",
    "print_board(view_board, view_grade.numpy())\n",
    "pred = model.eval()(board)[0].cpu()\n",
    "pred_numpy = pred.detach().numpy().reshape(7)\n",
    "pred_sig_numpy = torch.sigmoid(pred).detach().numpy().reshape(7)\n",
    "rounded_pred = np.round(pred_sig_numpy, 1)\n",
    "thresholded_pred = tuple(1 if x > 0 else 0 for x in pred_numpy)\n",
    "print(f\"NN Estimation: {list_to_grade[thresholded_pred]}\")\n",
    "print(f\"Full correct class: {view_grade.numpy()}\")\n",
    "print(f\"Model estim. class: {rounded_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc0948-df71-4223-b3ba-434b222988f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix for model\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_stats(model, iterator, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_plus_minus = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    pred_classes = []\n",
    "    true_classes = []\n",
    "\n",
    "    cf_pred = []\n",
    "    cf_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Creating confusion matrix from model\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            # convert matrix into class\n",
    "            for idx, item in enumerate(y_pred):\n",
    "                max_idx_pred = max([i+1 if x > 0 else 0 for i, x in enumerate(item)])\n",
    "                max_idx_true = max([i+1 if x > 0 else 0 for i, x in enumerate(y[idx])])\n",
    "                pred_classes.append(tuple([1 if idx == max_idx_pred else 0 for idx in range(len(item))]))\n",
    "                true_classes.append(tuple([1 if idx == max_idx_true else 0 for idx in range(len(item))]))\n",
    "                cf_pred.append(max_idx_pred)\n",
    "                cf_true.append(max_idx_true)\n",
    "\n",
    "    return confusion_matrix(cf_true, cf_pred), \\\n",
    "        roc_auc_score(true_classes, pred_classes, average='weighted', multi_class='ovr'), \\\n",
    "        f1_score(true_classes, pred_classes, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a60eaf-0572-4d86-b090-622d8957af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ticklabels = [\"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\", \"V10\", \"V11+\"]\n",
    "\n",
    "# get train set stats\n",
    "cf_matrix, auc, f1 = get_stats(model, train_iterator, device)\n",
    "cf_matrix_norm = cf_matrix.astype('float') / cf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(f\"Training set metrics:\")\n",
    "print(f\"AUC Score: {auc:0.4f} | F1 Score: {f1:0.4f}\")\n",
    "ax = sns.heatmap(cf_matrix_norm, annot=True, fmt='.0%', xticklabels=ticklabels, yticklabels=ticklabels)\n",
    "ax.set(xlabel=\"Predicted Labels\", ylabel=\"True Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce196731-1fa5-4ff4-b7f0-5a841e6ee687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get valid set stats\n",
    "cf_matrix, auc, f1 = get_stats(model, valid_iterator, device)\n",
    "cf_matrix_norm = cf_matrix.astype('float') / cf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(f\"Validation set metrics:\")\n",
    "print(f\"AUC Score: {auc:0.4f} | F1 Score: {f1:0.4f}\")\n",
    "ax = sns.heatmap(cf_matrix_norm, annot=True, fmt='.0%', xticklabels=ticklabels, yticklabels=ticklabels)\n",
    "ax.set(xlabel=\"Predicted Labels\", ylabel=\"True Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2644b6-3cd2-48fb-bf50-c0d9ab7aff58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
